<ns0:entry xmlns:ns0="http://www.w3.org/2005/Atom" xmlns:ns1="http://arxiv.org/schemas/atom">
    <ns0:id>http://arxiv.org/abs/1611.01874v2</ns0:id>
    <ns0:updated>2016-11-21T09:47:22Z</ns0:updated>
    <ns0:published>2016-11-07T02:03:55Z</ns0:published>
    <ns0:title>Neural Machine Translation with Reconstruction</ns0:title>
    <ns0:summary>  Although end-to-end Neural Machine Translation (NMT) has achieved remarkable
progress in the past two years, it suffers from a major drawback: translations
generated by NMT systems often lack of adequacy. It has been widely observed
that NMT tends to repeatedly translate some source words while mistakenly
ignoring other words. To alleviate this problem, we propose a novel
encoder-decoder-reconstructor framework for NMT. The reconstructor,
incorporated into the NMT model, manages to reconstruct the input source
sentence from the hidden layer of the output target sentence, to ensure that
the information in the source side is transformed to the target side as much as
possible. Experiments show that the proposed framework significantly improves
the adequacy of NMT output and achieves superior translation result over
state-of-the-art NMT and statistical MT systems.
</ns0:summary>
    <ns0:author>
      <ns0:name>Zhaopeng Tu</ns0:name>
    </ns0:author>
    <ns0:author>
      <ns0:name>Yang Liu</ns0:name>
    </ns0:author>
    <ns0:author>
      <ns0:name>Lifeng Shang</ns0:name>
    </ns0:author>
    <ns0:author>
      <ns0:name>Xiaohua Liu</ns0:name>
    </ns0:author>
    <ns0:author>
      <ns0:name>Hang Li</ns0:name>
    </ns0:author>
    <ns1:comment>Accepted by AAAI 2017</ns1:comment>
    <ns0:link href="http://arxiv.org/abs/1611.01874v2" rel="alternate" type="text/html" />
    <ns0:link title="pdf" href="http://arxiv.org/pdf/1611.01874v2" rel="related" type="application/pdf" />
    <ns1:primary_category term="cs.CL" scheme="http://arxiv.org/schemas/atom" />
    <ns0:category term="cs.CL" scheme="http://arxiv.org/schemas/atom" />
  </ns0:entry>
