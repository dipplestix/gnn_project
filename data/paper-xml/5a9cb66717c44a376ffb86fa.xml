<ns0:entry xmlns:ns0="http://www.w3.org/2005/Atom" xmlns:ns1="http://arxiv.org/schemas/atom">
    <ns0:id>http://arxiv.org/abs/1802.06655v2</ns0:id>
    <ns0:updated>2018-04-26T07:19:25Z</ns0:updated>
    <ns0:published>2018-02-19T14:49:42Z</ns0:published>
    <ns0:title>Tied Multitask Learning for Neural Speech Translation</ns0:title>
    <ns0:summary>  We explore multitask models for neural translation of speech, augmenting them
in order to reflect two intuitive notions. First, we introduce a model where
the second task decoder receives information from the decoder of the first
task, since higher-level intermediate representations should provide useful
information. Second, we apply regularization that encourages transitivity and
invertibility. We show that the application of these notions on jointly trained
models improves performance on the tasks of low-resource speech transcription
and translation. It also leads to better performance when using attention
information for word discovery over unsegmented input.
</ns0:summary>
    <ns0:author>
      <ns0:name>Antonios Anastasopoulos</ns0:name>
    </ns0:author>
    <ns0:author>
      <ns0:name>David Chiang</ns0:name>
    </ns0:author>
    <ns1:comment>accepted at NAACL-HLT 2018</ns1:comment>
    <ns0:link href="http://arxiv.org/abs/1802.06655v2" rel="alternate" type="text/html" />
    <ns0:link title="pdf" href="http://arxiv.org/pdf/1802.06655v2" rel="related" type="application/pdf" />
    <ns1:primary_category term="cs.CL" scheme="http://arxiv.org/schemas/atom" />
    <ns0:category term="cs.CL" scheme="http://arxiv.org/schemas/atom" />
  </ns0:entry>
