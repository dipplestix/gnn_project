<ns0:entry xmlns:ns0="http://www.w3.org/2005/Atom" xmlns:ns1="http://arxiv.org/schemas/atom">
    <ns0:id>http://arxiv.org/abs/1712.09665v2</ns0:id>
    <ns0:updated>2018-05-17T01:44:59Z</ns0:updated>
    <ns0:published>2017-12-27T20:03:51Z</ns0:published>
    <ns0:title>Adversarial Patch</ns0:title>
    <ns0:summary>  We present a method to create universal, robust, targeted adversarial image
patches in the real world. The patches are universal because they can be used
to attack any scene, robust because they work under a wide variety of
transformations, and targeted because they can cause a classifier to output any
target class. These adversarial patches can be printed, added to any scene,
photographed, and presented to image classifiers; even when the patches are
small, they cause the classifiers to ignore the other items in the scene and
report a chosen target class.
  To reproduce the results from the paper, our code is available at
https://github.com/tensorflow/cleverhans/tree/master/examples/adversarial_patch
</ns0:summary>
    <ns0:author>
      <ns0:name>Tom B. Brown</ns0:name>
    </ns0:author>
    <ns0:author>
      <ns0:name>Dandelion Man&#233;</ns0:name>
    </ns0:author>
    <ns0:author>
      <ns0:name>Aurko Roy</ns0:name>
    </ns0:author>
    <ns0:author>
      <ns0:name>Mart&#237;n Abadi</ns0:name>
    </ns0:author>
    <ns0:author>
      <ns0:name>Justin Gilmer</ns0:name>
    </ns0:author>
    <ns0:link href="http://arxiv.org/abs/1712.09665v2" rel="alternate" type="text/html" />
    <ns0:link title="pdf" href="http://arxiv.org/pdf/1712.09665v2" rel="related" type="application/pdf" />
    <ns1:primary_category term="cs.CV" scheme="http://arxiv.org/schemas/atom" />
    <ns0:category term="cs.CV" scheme="http://arxiv.org/schemas/atom" />
  </ns0:entry>
