<ns0:entry xmlns:ns0="http://www.w3.org/2005/Atom" xmlns:ns1="http://arxiv.org/schemas/atom">
    <ns0:id>http://arxiv.org/abs/1906.00910v2</ns0:id>
    <ns0:updated>2019-07-08T16:41:31Z</ns0:updated>
    <ns0:published>2019-06-03T16:24:57Z</ns0:published>
    <ns0:title>Learning Representations by Maximizing Mutual Information Across Views</ns0:title>
    <ns0:summary>  We propose an approach to self-supervised representation learning based on
maximizing mutual information between features extracted from multiple views of
a shared context. For example, one could produce multiple views of a local
spatio-temporal context by observing it from different locations (e.g., camera
positions within a scene), and via different modalities (e.g., tactile,
auditory, or visual). Or, an ImageNet image could provide a context from which
one produces multiple views by repeatedly applying data augmentation.
Maximizing mutual information between features extracted from these views
requires capturing information about high-level factors whose influence spans
multiple views -- e.g., presence of certain objects or occurrence of certain
events.
  Following our proposed approach, we develop a model which learns image
representations that significantly outperform prior methods on the tasks we
consider. Most notably, using self-supervised learning, our model learns
representations which achieve 68.1% accuracy on ImageNet using standard linear
evaluation. This beats prior results by over 12% and concurrent results by 7%.
When we extend our model to use mixture-based representations, segmentation
behaviour emerges as a natural side-effect. Our code is available online:
https://github.com/Philip-Bachman/amdim-public.
</ns0:summary>
    <ns0:author>
      <ns0:name>Philip Bachman</ns0:name>
    </ns0:author>
    <ns0:author>
      <ns0:name>R Devon Hjelm</ns0:name>
    </ns0:author>
    <ns0:author>
      <ns0:name>William Buchwalter</ns0:name>
    </ns0:author>
    <ns0:link href="http://arxiv.org/abs/1906.00910v2" rel="alternate" type="text/html" />
    <ns0:link title="pdf" href="http://arxiv.org/pdf/1906.00910v2" rel="related" type="application/pdf" />
    <ns1:primary_category term="cs.LG" scheme="http://arxiv.org/schemas/atom" />
    <ns0:category term="cs.LG" scheme="http://arxiv.org/schemas/atom" />
    <ns0:category term="stat.ML" scheme="http://arxiv.org/schemas/atom" />
  </ns0:entry>
