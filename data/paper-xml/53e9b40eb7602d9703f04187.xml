<ns0:entry xmlns:ns0="http://www.w3.org/2005/Atom" xmlns:ns1="http://arxiv.org/schemas/atom">
    <ns0:id>http://arxiv.org/abs/1311.2901v3</ns0:id>
    <ns0:updated>2013-11-28T23:04:01Z</ns0:updated>
    <ns0:published>2013-11-12T20:02:22Z</ns0:published>
    <ns0:title>Visualizing and Understanding Convolutional Networks</ns0:title>
    <ns0:summary>  Large Convolutional Network models have recently demonstrated impressive
classification performance on the ImageNet benchmark. However there is no clear
understanding of why they perform so well, or how they might be improved. In
this paper we address both issues. We introduce a novel visualization technique
that gives insight into the function of intermediate feature layers and the
operation of the classifier. We also perform an ablation study to discover the
performance contribution from different model layers. This enables us to find
model architectures that outperform Krizhevsky \etal on the ImageNet
classification benchmark. We show our ImageNet model generalizes well to other
datasets: when the softmax classifier is retrained, it convincingly beats the
current state-of-the-art results on Caltech-101 and Caltech-256 datasets.
</ns0:summary>
    <ns0:author>
      <ns0:name>Matthew D Zeiler</ns0:name>
    </ns0:author>
    <ns0:author>
      <ns0:name>Rob Fergus</ns0:name>
    </ns0:author>
    <ns0:link href="http://arxiv.org/abs/1311.2901v3" rel="alternate" type="text/html" />
    <ns0:link title="pdf" href="http://arxiv.org/pdf/1311.2901v3" rel="related" type="application/pdf" />
    <ns1:primary_category term="cs.CV" scheme="http://arxiv.org/schemas/atom" />
    <ns0:category term="cs.CV" scheme="http://arxiv.org/schemas/atom" />
  </ns0:entry>
