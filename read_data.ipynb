{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open('data/paper_source_trace_train_ans.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5bdc316717c44a1f58a06f07',\n",
       " '58d82fcbd649053542fd67e0',\n",
       " '53e9a525b7602d9702e4a2f9',\n",
       " '58437722ac44360f1082f5bd',\n",
       " '5a9cb60d17c44a376ffb3c4c',\n",
       " '5bdc31b417c44a1f58a0b8c2',\n",
       " '53e9ae89b7602d97038a8a5b',\n",
       " '53e9b457b7602d9703f54cf4',\n",
       " '53e9bafbb7602d970473014e',\n",
       " '53e9b9dab7602d97045d5eb7',\n",
       " '53e9affab7602d9703a4f291',\n",
       " '53e9a7feb7602d9703140daa',\n",
       " '5b8c9f4a17c44af36f8b72cf',\n",
       " '573697556e3b12023e63e8e4',\n",
       " '5d270c39275ded87f9541e2b',\n",
       " '5736973c6e3b12023e62b744',\n",
       " '53e9bbcfb7602d970481a6ec',\n",
       " '573696016e3b12023e514a63',\n",
       " '573697556e3b12023e63e9e3',\n",
       " '53e9acc4b7602d97036a1037',\n",
       " '573698636e3b12023e729d7c',\n",
       " '5dea04309e795e693620e97c',\n",
       " '53e9baecb7602d970471fc05',\n",
       " '558b4cb5612c41e6b9d48858']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['references']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: None\n",
      "Author: Zhenwei Shi\n",
      "Author: G Cheng\n",
      "Author: J Han\n",
      "Author: Z Shi\n",
      "Author: X Yu\n",
      "Author: Z Jiang\n",
      "Author: B Li\n",
      "Author: L Liu\n",
      "Author: Z Shi\n",
      "Author: J Han\n",
      "Author: G Cheng\n",
      "Author: J Han\n",
      "Author: P Zhou\n",
      "Author: L Guo\n",
      "Author: X Yu\n",
      "Author: Z Shi\n",
      "Author: F Zhang\n",
      "Author: B Du\n",
      "Author: L Zhang\n",
      "Author: M Xu\n",
      "Author: J Han\n",
      "Author: D Zhang\n",
      "Author: G Cheng\n",
      "Author: L Guo\n",
      "Author: J Ren\n",
      "Author: L Zhang\n",
      "Author: Z Shi\n",
      "Author: J Wu\n",
      "Author: G Cheng\n",
      "Author: P Zhou\n",
      "Author: J Han\n",
      "Author: Z Zou\n",
      "Author: Z Shi\n",
      "Author: Z Shi\n",
      "Author: Z Zou\n",
      "Author: H Lin\n",
      "Author: Z Shi\n",
      "Author: Z Zou\n",
      "Author: D Manolakis\n",
      "Author: D Marden\n",
      "Author: G Shaw\n",
      "Author: R Feynman\n",
      "Author: R Leighton\n",
      "Author: M Sands\n",
      "Author: R Lindsay\n",
      "Author: C Bishop\n",
      "Author: C Rasmussen\n",
      "Author: C Williams\n",
      "Author: K Murphy\n",
      "Author: A Krizhevsky\n",
      "Author: I Sutskever\n",
      "Author: G Hinton\n",
      "Author: K Simonyan\n",
      "Author: A Zisserman\n",
      "Author: K He\n",
      "Author: X Zhang\n",
      "Author: S Ren\n",
      "Author: J Sun\n",
      "Author: P Viola\n",
      "Author: M Jones\n",
      "Author: P Viola\n",
      "Author: M Jones\n",
      "Author: N Dalal\n",
      "Author: B Triggs\n",
      "Author: P Felzenszwalb\n",
      "Author: D Mcallester\n",
      "Author: D Ramanan\n",
      "Author: P Felzenszwalb\n",
      "Author: R Girshick\n",
      "Author: D Mcallester\n",
      "Author: D Ramanan\n",
      "Author: R Girshick\n",
      "Author: J Donahue\n",
      "Author: T Darrell\n",
      "Author: J Malik\n",
      "Author: R Girshick\n",
      "Author: K He\n",
      "Author: X Zhang\n",
      "Author: S Ren\n",
      "Author: J Sun\n",
      "Author: S Ren\n",
      "Author: K He\n",
      "Author: R Girshick\n",
      "Author: J Sun\n",
      "Author: J Redmon\n",
      "Author: S Divvala\n",
      "Author: R Girshick\n",
      "Author: A Farhadi\n",
      "Author: D Yoo\n",
      "Author: S Park\n",
      "Author: J.-Y Lee\n",
      "Author: A Paek\n",
      "Author: I Kweon\n",
      "Author: S Gidaris\n",
      "Author: N Komodakis\n",
      "Author: A Shrivastava\n",
      "Author: A Gupta\n",
      "Author: R Girshick\n",
      "Author: P Dollár\n",
      "Author: Z Tu\n",
      "Author: P Perona\n",
      "Author: S Belongie\n",
      "Author: P Dollár\n",
      "Author: R Appel\n",
      "Author: S Belongie\n",
      "Author: P Perona\n",
      "Author: Q Zhu\n",
      "Author: M.-C Yeh\n",
      "Author: K.-T Cheng\n",
      "Author: S Avidan\n",
      "Author: R Benenson\n",
      "Author: M Mathias\n",
      "Author: R Timofte\n",
      "Author: L Van Gool\n",
      "Author: W Liu\n",
      "Author: J Redmon\n",
      "Author: A Farhadi\n",
      "Author: L Zhang\n",
      "Author: L Zhang\n",
      "Author: B Du\n",
      "Author: Z Cai\n",
      "Author: Q Fan\n",
      "Author: R Feris\n",
      "Author: N Vasconcelos\n",
      "Author: T.-Y Lin\n",
      "Author: P Dollár\n",
      "Author: R Girshick\n",
      "Author: K He\n",
      "Author: B Hariharan\n",
      "Author: S Belongie\n",
      "Author: T Kong\n",
      "Author: A Yao\n",
      "Author: Y Chen\n",
      "Author: F Sun\n",
      "Author: S Bell\n",
      "Author: C Zitnick\n",
      "Author: K Bala\n",
      "Author: R Girshick\n",
      "Author: I Goodfellow\n",
      "Author: Y Bengio\n",
      "Author: A Courville\n",
      "Author: Deep Learning\n",
      "Author: A Vedaldi\n",
      "Author: K Lenc\n",
      "Author: G Heitz\n",
      "Author: D Koller\n",
      "Author: F Tanner\n",
      "Author: A Kembhavi\n",
      "Author: D Harwood\n",
      "Author: L Davis\n",
      "Abstract:\n",
      "\n",
      "Main Text:\n",
      "Abstract-We propose a new paradigm for target detection in high resolution aerial remote sensing images under small target priors. Previous remote sensing target detection methods frame the detection as learning of detection model + inference of classlabel and bounding-box coordinates. Instead, we formulate it from a Bayesian view that at inference stage, the detection model is adaptively updated to maximize its posterior that is determined by both training and observation. We call this paradigm \"random access memories (RAM).\" In this paradigm, \"Memories\" can be interpreted as any model distribution learned from training data and \"random access\" means accessing memories and randomly adjusting the model at detection phase to obtain better adaptivity to any unseen distribution of test data. By leveraging some latest detection techniques e.g., deep Convolutional Neural Networks and multi-scale anchors, experimental results on a public remote sensing target detection data set show our method outperforms several other state of the art methods. We also introduce a new data set \"LEarning, VIsion and Remote sensing laboratory (LEVIR)\", which is one order of magnitude larger than other data sets of this field. LEVIR consists of a large set of Google Earth images, with over 22 k images and 10 k independently labeled targets. RAM gives noticeable upgrade of accuracy (an mean average precision improvement of 1% ∼ 4%) of our baseline detectors with acceptable computational overhead. Index Terms-High resolution aerial remote sensing image, target detection, convolutional neural networks, random access memories.\n",
      "\n",
      "I. INTRODUCTION\n",
      "T HE rapid development of remote sensing technologies has opened a door for people to observe the earth. Automatically detecting targets of remote sensing images, e.g. the airplane, oilpot and ship, is one of the core tasks in remote sensing applications, and have been drawing more and more attentions in recent years \n",
      "Most of the early attempts of remote sensing target detection \n",
      "\n",
      "A. Random Access Memories (RAM)\n",
      "Here we re-think the detection paradigm by assuming that detection model can be changed adaptively as the model receives different observations. This idea is inspired by a large group of detection algorithms of signal process field called the Constant False Alarm Rate algorithms \n",
      "\n",
      "B. Approximate Inference\n",
      "Most of the CNN based detectors are built on basis of frequentist statistics, where their detection model can be explicitly determined by the local/global maximum of the likelihood during the training phase. Instead, the proposed paradigm is established based on a complete probability distribution of the detection model. In Bayesian machine learning, Laplace Approximation \n",
      "\n",
      "C. The Small Target Prior in Remote Sensing Image\n",
      "For high resolution aerial remote sensing images, the targets of interest are usually sparse distributed and only occupy a very small number of pixels. In the case of sliding window based detectors, the imbalance between background and desired target could be as extreme as 10 7 background windows to every target window. This could be even true for wide-scale remote sensing images. The complex background distribution leads to a higher demand on the capacity of the model. Larger models are able to capture more complex background distributions, while it may suffer from a higher computation cost, which is especially infeasible for some on-orbit remote sensing applications. An advantage of our method lies that the small target prior can be very easily integrated to the proposed paradigm, as we are able to compress model's capacity to meet the speed requirement while maintaining the detection accuracy.\n",
      "\n",
      "D. Contributions\n",
      "The contributions of our work can be summarized as follows:\n",
      "1) The key innovation of Random Access Memories lies that the detection model can be adaptively changed during detection phase that contemporarily determined by both training and the latest observations. Such paradigm can be easily integrated with the current CNN based detectors without complex changes. With RAM, a comparable or even higher detection accuracy of a larger model can be obtained with less parameters and a faster detection speed. 2) We introduce a new dataset \"LEVIR\"\n",
      "\n",
      "II. RECENT ADVANCES IN NATURAL IMAGE OBJECT DETECTION\n",
      "In computer vision, there has been great progress of natural image object detection methods in recent years. Recent advances of deep CNN \n",
      "For multi-scale detection, the most straight forward way is to build feature map pyramids \n",
      "Despite that great efforts have been made, for some important remote sensing applications such as wide-scale remote sensing monitoring or even on-orbit target detection, these algorithms are still far from being practical at present due to the complex background features, drastically changes of the target scales \n",
      "\n",
      "III. RANDOM ACCESS MEMORIES\n",
      "In this section, we will give a detailed description to our detection paradigm and explain how it works with a CNN based detector.\n",
      "\n",
      "A. Fisher Information\n",
      "The training process of any target detector is essentially a likelihood estimation process. Here we follow a classical learning paradigm that the optimal model Ĥ can be determined by the i.i.d. training data D tr and the model's hypothesis space F Ĥ = argmax H∈F p(D tr |H).\n",
      "(\n",
      "For any early sliding window based detectors \n",
      "which is equivalent to the second derivative (if it exists) of the negative log likelihood function. I(θ ) can be viewed as a measurement of the \"curvature\" of the support curve near the MLE point θ , where a \"blunt\" support curve (one with a shallow maximum) could have a low negative expected second derivative, and thus low information, while a sharp one could have a high information.\n",
      "For a detection model H with multiple parameters θ = [θ 1 , θ 2 , . . . , θ N ] T , the fisher information can be written as its matrix form I( Ĥ), where its element-wise representation is\n",
      "I( Ĥ) is equivalent to the Hessian matrix (if it exists) of the negative log likelihood function. It can be also understood as a metric of an appropriate changes of any variables induced from the Euclidean metric.\n",
      "\n",
      "B. Laplace Approximation\n",
      "Here we use a simple but widely used framework called the Laplace approximation, that aims to find a Gaussian approximation to a probability density defined over a set of continuous variables \n",
      "In this way, the probability value at any changes of the model can be represented as\n",
      "where\n",
      "represents the I( Ĥ) norm metric of the model changes.\n",
      "\n",
      "C. Updating Memories\n",
      "The fisher information can be regarded as a very important prior that guides the update of the model. During detection phase, the detection model Ĥ will be changed according to both of the approximated distribution (4) and the observation D ob . The posterior distribution of H can be represented as\n",
      "By dividing the likelihood function p(D ob |H) into the positive part (target of interest D + ob ) and negative part Fig. \n",
      "(undesired background D - ob ), and substituting (5) into p(H), the posterior can be expanded as\n",
      "For any latest observations, the model should be updated to access the maximum of posterior to best fit the training and testing data at the same time\n",
      "Clearly, for some directions of I( Ĥ), a slight change of the model δH would cause a rapid decline of the probability p(H|D ob ), while for some other directions the probability may keep stable. Fig. \n",
      "\n",
      "D. Integrating the Small Target Priors\n",
      "It is hard to optimize (8) directly since it contains latent variables D + ob and D - ob , where \"+\" and \"-\" represent the latent labels. Since the amount of the negatives are usually far greater than the positives for a remote sensing image: N -N + , we are reasonable to neglect the positive latent variables. In this way, (8) can be relaxed to its negative logarithmic likelihood , \n",
      "can be seen as a constraint which controls the update range of the model. α > 0 is a positive number controls the degree of the constraint.\n",
      "Despite the latent variables has been eliminated, another problem lies that the high dimensional parameter space of a deep CNN makes it still very difficult to directly compute and store the fisher information matrix I( Ĥ). A further assumption can be made that only a small portion of the memories are updated during detection phase. Here we take a simple and straightforward manner, that only optimizing the parameters of the final output layer while keeping those of previous layers fixed as feature extractor. More specifically, when a testing image is fed into the network, passing through all convolutional layers and finally comes to the full-connected layer, the RAM operation should be performed. Since the regularization H -Ĥ 2\n",
      "is always convex at any local/gobal maximum point, any types of the convex loss functions of -log( p(D|θ )), e.g. square loss, smoothed L1 loss \n",
      "\n",
      "E. Implementation Details\n",
      "Fig. \n",
      "1) Backbone: Current CNN based object detection methods can be divided into two important branches based on their processing flow. The first branch is cascaded detectors where the detection is performed from a coarse to fine manner \n",
      "2) Loss Layer Design: We follow the idea of pre-defined anchors for multi-scale detection \n",
      "We use the parameterized coordinates as it was used in \n",
      "For category scoring, we also simply see it as a score regression problem with the smoothed L1 loss. Similar ideas have been used in \n",
      "where x refers to the features of the last convolutional layer, θ and y refer to the convolutional filters and ground-truth label of specific category and anchor-scale. Then the optimization  \n",
      "The above optimization problem has an approximated closed form solution:\n",
      "where C and I( Ĥ) has the following expression:\n",
      "In this way, the model can be updated easily without any iterative operations.\n",
      "\n",
      "IV. LEVIR: A NEW DATASET FOR REMOTE SENSING TARGET DETECTION\n",
      "Large and challenging datasets are necessary for the progress in remote sensing applications. Our goal in introducing the LEVIR detection dataset is to provide a better benchmark and statistically meaningful evaluations for those current and future detection methods.\n",
      "LEVIR consists of a large number of high resolution Google Earth images with over 22k images of 800 × 600 pixels and 0.2m ∼ 1.0m/pixel's resolution. LEVIR covers most types of ground features of human living environment, e.g. city, country, mountain area and ocean. Extreme land environments such as glacier, desert and gobi are not considered in our dataset. There are 3 types of targets in our dataset: airplane, ship (including both inshore ships and offshore ships) and oilpot. We label all the images for a total of 11k independent bounding boxes (BB) including 4,724 airplanes, 3,025 ships and 3,279 oilpots. The average number of targets per image is 0.5. For every image in which a given target of interest is visible, we draw a tight BB that indicates the full extent of the entire target. It should be noticed that for those targets that are partially outside the image boundary or occluded by other objects, this involves estimating the location of hidden parts. A summary of our dataset is given in Table . I. During the last decades, some efforts have been made to develop public dataset for target detection from aerial and satellite images. Here we list the detailed overview of three public available datasets:\n",
      "NWPU-VHR-10 \n",
      "TAS Aerial Car Detection Dataset (TACDD) \n",
      "Overhead Imagery Research Dataset (OIRDS) \n",
      "Table \n",
      "\n",
      "V. EXPERIMENTAL RESULTS AND ANALYSIS\n",
      "In this section, we have made an extensive evaluation and comparison with several variants of our model and other detection methods. Our experiments are performed on LEVIR and NWPU-VHR-10. For LEVIR, 70% images are used for training and rests are used for test. For NWPU-VHR-10, we use the same training-testing split criterion with other comparison methods as they originally used in their paper.\n",
      "\n",
      "A. Training Details 1) Data Augmentation:\n",
      "To detect targets with different directions, each individual target is randomly rotated for several times and then randomly resized and translated to make sure that there are sufficient information for each anchor-scale to learn. We use the similar criterion that is used in \n",
      "2) Pre-Training: For our large-sized model, the initial weight is transferred from that of VGG-f which is trained on the ImageNet. For our tiny-sized and medium-sized models, the networks are first pre-trained with targets and randomly generated backgrounds. The training is performed for 20 epochs by back-propagation and stochastic gradient descent (SGD) \n",
      "3) Hard-Negative Mining: After pre-training, we fine-tune the model, where in each mining iteration the training set is augmented with hard negative examples. We assign a background label to any detected false negative anchor if its IoU overlap is lower than 0.2 for all ground-truth BBs. Anchors that are neither positive nor negative do not contribute to the training. In each mining iteration, the detector collects over 500 hard negatives and the SGD is performed for 2 epochs.\n",
      "4) Multi-Octave Detection: Although recent advances \n",
      "\n",
      "B. Overall Results Statistics 1) Comparisons With Baselines:\n",
      "For fair comparisons with our paradigm, we have designed three baseline methods:\n",
      "Baseline 1: tiny-networks (TINY-BASE), • Baseline 2: medium-networks (MEDIUM-BASE),\n",
      "• Baseline 3: VGG-f based networks (LARGE-BASE), and their improved variants with memories-updating:\n",
      "• Proposed 1: tiny-networks+ram (TINY-RAM),\n",
      "• Proposed 2: medium-networks+ram (MEDIUM-RAM),\n",
      "• Proposed 3: VGG-f based networks+ram (LARGE-RAM). During evaluation, some ambiguous instances are excluded from our dataset. There are two kinds of situations that we identify it as an ambiguous target. The first type is that the targets bounding-box are partially clustered or outside (larger than 3/4 of its area) the image. The second type refers to the instance with very small size, whose length is smaller than 20 pixels. To detect smaller target, we suggest using higher resolution images. Any false detection or missing of these targets will not be taken into account neither as a false positive nor as a true positive. \n",
      "\n",
      "TABLE IV COMPARISONS OF THE PROPOSED METHODS AND THEIR BASELINES\n",
      "All comparisons use the same settings including networks' hyperparameters, training parameters and detection parameters. Table \n",
      "Fig. \n",
      "2) Comparisons on NWPU-VHR-10: We also evaluate the performance of our method on NWPU-VHR-10 dataset and compare with other state-of-the-art remote sensing detection methods e.g. RICNN \n",
      "We use the same training-testing split criterion as those was used in \n",
      "3) How Important is Fisher Information?: The way to compute the fisher information matrix is a key point of our method that it describes how well the model distribution is approximated at its MLE point. In this experiment, we give two approximation forms to its original one: 1) the diagonal matrix approximation where only its diagonal elements are left while others are set zeros and 2) the identity matrix approximation where the matrix is further simplified as an identity matrix. Table \n",
      "\n",
      "4) Hyper-Parameter Stability:\n",
      "The regularization coefficient α of (9) serves as a very important hyper-parameter in our method. Fig. \n",
      "5) Speed Performance: We test our method on an Intel i7 PC with a Nvidia GTX 1080Ti graphics card. We use the GPU to accelerate the training and detection process. The training process takes a few hours to days on various sized models. For a 800 × 600 sized input image, a fast version of our method only takes about 0.1s (10fps) to finish the forward pass (0.02s) + memories updating process (0.10s). Table VII lists the total detection time and memory updating time of the baseline methods and the proposed four variants. For RICNN and FDDL, the running time is reported by their authors, and the testing image is about the same size. The authors of COPD did not report their time. All our models run much faster in spite that the memory updating process takes the most of the running time. The main time cost when updating memories is from the matrix inversion operation in \n",
      "With random access the memories, we can obtain a comparable or even higher detection accuracy of a larger model with less parameters and a faster detection speed. For example, in Table \n",
      "\n",
      "VI. CONCLUSION\n",
      "We propose a new paradigm called \"Random Access Memories\" for target detection for high resolution aerial remote sensing image. We also provide a new challenging dataset for remote sensing target detection which is one order of magnitude larger than existing datasets. Experiments have confirmed the validity of the proposed paradigm where noticeable improvements over a CNN based detectors can be observed. The proposed method outperforms several other state-of-the-art remote sensing target detection methods. Besides, RAM may open some novel opportunities of investigation in other applications under small target priors, such as the fast detection of natural image objects, instance segmentation and even image retrieval tasks.\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Parse the XML file\n",
    "tree = ET.parse('/Users/chris/Desktop/Projects/gnn_project/data/paper-xml/5a2c9c630cf2a5ba891f9b17.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "# Define the XML namespace\n",
    "ns = {'tei': 'http://www.tei-c.org/ns/1.0'}\n",
    "\n",
    "# Extract title\n",
    "title = root.find('.//tei:title[@level=\"a\"][@type=\"main\"]', ns).text\n",
    "print(f\"Title: {title}\")\n",
    "\n",
    "# Extract authors\n",
    "authors = root.findall('.//tei:author', ns)\n",
    "for author in authors:\n",
    "    name = author.find('.//tei:persName', ns)\n",
    "    if name is not None:\n",
    "        forename = name.find('tei:forename', ns).text\n",
    "        surname = name.find('tei:surname', ns).text\n",
    "        print(f\"Author: {forename} {surname}\")\n",
    "\n",
    "# Extract abstract\n",
    "abstract = root.find('.//tei:abstract', ns)\n",
    "if abstract is not None:\n",
    "    print(\"Abstract:\")\n",
    "    for p in abstract.findall('tei:p', ns):\n",
    "        print(p.text)\n",
    "\n",
    "# Extract main text\n",
    "body = root.find('.//tei:body', ns)\n",
    "if body is not None:\n",
    "    print(\"\\nMain Text:\")\n",
    "    for div in body.findall('tei:div', ns):\n",
    "        head = div.find('tei:head', ns)\n",
    "        if head is not None:\n",
    "            print(f\"\\n{head.text}\")\n",
    "        for p in div.findall('tei:p', ns):\n",
    "            print(p.text)\n",
    "\n",
    "# You can add more extraction logic as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
