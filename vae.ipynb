{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST data loaded successfully.\n",
      "Number of training samples: 60000\n",
      "Number of test samples: 10000\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define the device (GPU if available, else CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Download and load the MNIST dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"MNIST data loaded successfully.\")\n",
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "print(f\"Number of test samples: {len(test_dataset)}\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, latent_dim*2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        return self.encoder(x)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 28 * 28),\n",
    "            nn.Sigmoid()    \n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, hidden_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(hidden_dim, latent_dim)\n",
    "        self.decoder = Decoder(hidden_dim, latent_dim)\n",
    "\n",
    "    def sample_z(self, mean, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mean + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        mean, log_var = z.chunk(2, dim=1)\n",
    "        z = self.sample_z(mean, log_var)\n",
    "        x_reconstructed = self.decoder(z)\n",
    "        x_reconstructed = x_reconstructed.view(-1, 1, 28, 28)\n",
    "        return x_reconstructed, mean, log_var\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 558928\n",
      "Trainable parameters: 558928\n"
     ]
    }
   ],
   "source": [
    "v = VAE(hidden_dim=256, latent_dim=32).to(device)\n",
    "# Count the parameters\n",
    "total_params = sum(p.numel() for p in v.parameters())\n",
    "trainable_params = sum(p.numel() for p in v.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "print(f\"Trainable parameters: {trainable_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(x_reconstructed, x, mean, log_var):\n",
    "    BCE = F.binary_cross_entropy(x_reconstructed, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
    "    return BCE + KLD\n",
    "\n",
    "v = VAE(hidden_dim=256, latent_dim=32).to(device)\n",
    "optimizer = optim.Adam(v.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch 1 Average loss: 188.2999915201823\n",
      "====> Test set loss: 150.9577\n",
      "====> Epoch 2 Average loss: 137.54103987630208\n",
      "====> Test set loss: 126.4838\n",
      "====> Epoch 3 Average loss: 123.184259375\n",
      "====> Test set loss: 119.4769\n",
      "====> Epoch 4 Average loss: 117.43079288736979\n",
      "====> Test set loss: 114.5551\n",
      "====> Epoch 5 Average loss: 113.82113878580729\n",
      "====> Test set loss: 111.4514\n",
      "====> Epoch 6 Average loss: 111.37684646809896\n",
      "====> Test set loss: 109.7999\n",
      "====> Epoch 7 Average loss: 109.65817451171876\n",
      "====> Test set loss: 108.3640\n",
      "====> Epoch 8 Average loss: 108.3569681640625\n",
      "====> Test set loss: 107.3817\n",
      "====> Epoch 9 Average loss: 107.37752573242187\n",
      "====> Test set loss: 106.6350\n",
      "====> Epoch 10 Average loss: 106.596666796875\n",
      "====> Test set loss: 105.8866\n",
      "====> Epoch 11 Average loss: 105.93763649088541\n",
      "====> Test set loss: 105.2639\n",
      "====> Epoch 12 Average loss: 105.38324931640625\n",
      "====> Test set loss: 105.2463\n",
      "====> Epoch 13 Average loss: 104.89503422851563\n",
      "====> Test set loss: 104.5834\n",
      "====> Epoch 14 Average loss: 104.49976188151042\n",
      "====> Test set loss: 104.1225\n",
      "====> Epoch 15 Average loss: 104.1370063313802\n",
      "====> Test set loss: 103.9928\n",
      "====> Epoch 16 Average loss: 103.73936650390625\n",
      "====> Test set loss: 103.8210\n",
      "====> Epoch 17 Average loss: 103.452798828125\n",
      "====> Test set loss: 103.5038\n",
      "====> Epoch 18 Average loss: 103.20469594726562\n",
      "====> Test set loss: 103.4255\n",
      "====> Epoch 19 Average loss: 102.95062088216146\n",
      "====> Test set loss: 102.9447\n",
      "====> Epoch 20 Average loss: 102.74954189453125\n",
      "====> Test set loss: 103.1151\n",
      "====> Epoch 21 Average loss: 102.47773377278646\n",
      "====> Test set loss: 102.7877\n",
      "====> Epoch 22 Average loss: 102.31479173177084\n",
      "====> Test set loss: 102.5337\n",
      "====> Epoch 23 Average loss: 102.10980099283854\n",
      "====> Test set loss: 102.4215\n",
      "====> Epoch 24 Average loss: 101.92870227864583\n",
      "====> Test set loss: 102.4174\n",
      "====> Epoch 25 Average loss: 101.77559345703125\n",
      "====> Test set loss: 102.1209\n",
      "====> Epoch 26 Average loss: 101.61568315429687\n",
      "====> Test set loss: 102.1729\n",
      "====> Epoch 27 Average loss: 101.45829521484374\n",
      "====> Test set loss: 102.0997\n",
      "====> Epoch 28 Average loss: 101.35109428710938\n",
      "====> Test set loss: 101.8805\n",
      "====> Epoch 29 Average loss: 101.19928478190104\n",
      "====> Test set loss: 101.6543\n",
      "====> Epoch 30 Average loss: 101.06250458984375\n",
      "====> Test set loss: 101.8184\n",
      "====> Epoch 31 Average loss: 100.97978118489583\n",
      "====> Test set loss: 101.7570\n",
      "====> Epoch 32 Average loss: 100.84409514973959\n",
      "====> Test set loss: 101.4139\n",
      "====> Epoch 33 Average loss: 100.69484985351562\n",
      "====> Test set loss: 101.5954\n",
      "====> Epoch 34 Average loss: 100.6418130859375\n",
      "====> Test set loss: 101.5182\n",
      "====> Epoch 35 Average loss: 100.5421904296875\n",
      "====> Test set loss: 101.1657\n",
      "====> Epoch 36 Average loss: 100.46169028320313\n",
      "====> Test set loss: 101.2103\n",
      "====> Epoch 37 Average loss: 100.36991702473958\n",
      "====> Test set loss: 101.3160\n",
      "====> Epoch 38 Average loss: 100.2789080078125\n",
      "====> Test set loss: 101.1849\n",
      "====> Epoch 39 Average loss: 100.17756997070312\n",
      "====> Test set loss: 101.2116\n",
      "====> Epoch 40 Average loss: 100.11364993489583\n",
      "====> Test set loss: 101.1001\n",
      "====> Epoch 41 Average loss: 100.04505825195312\n",
      "====> Test set loss: 101.4596\n",
      "====> Epoch 42 Average loss: 99.96950607096355\n",
      "====> Test set loss: 101.0562\n",
      "====> Epoch 43 Average loss: 99.90860133463542\n",
      "====> Test set loss: 100.8327\n",
      "====> Epoch 44 Average loss: 99.8043572265625\n",
      "====> Test set loss: 100.8752\n",
      "====> Epoch 45 Average loss: 99.73394220377604\n",
      "====> Test set loss: 101.1706\n",
      "====> Epoch 46 Average loss: 99.72686982421875\n",
      "====> Test set loss: 100.8033\n",
      "====> Epoch 47 Average loss: 99.64359220377604\n",
      "====> Test set loss: 101.1610\n",
      "====> Epoch 48 Average loss: 99.6032734375\n",
      "====> Test set loss: 100.5851\n",
      "====> Epoch 49 Average loss: 99.50929819335937\n",
      "====> Test set loss: 100.7417\n"
     ]
    }
   ],
   "source": [
    "def train(epoch):\n",
    "    v.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        x_reconstructed, mean, log_var = v(data)\n",
    "        loss = loss_function(x_reconstructed, data, mean, log_var)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    print(f\"====> Epoch {epoch} Average loss: {train_loss / len(train_loader.dataset)}\")\n",
    "\n",
    "def test():\n",
    "    v.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            x_reconstructed, mean, log_var = v(data)\n",
    "            x_reconstructed = torch.clamp(x_reconstructed, 0, 1)  # Ensure values are between 0 and 1\n",
    "            test_loss += loss_function(x_reconstructed, data, mean, log_var).item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f\"====> Test set loss: {test_loss:.4f}\")\n",
    "\n",
    "for epoch in range(1, 50):\n",
    "    train(epoch)\n",
    "    test()  # Added test() call after each epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvEncoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.conv_encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 4 * 4, latent_dim * 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_encoder(x)\n",
    "\n",
    "class ConvDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.decoder_linear = nn.Linear(latent_dim, 64 * 4 * 4)\n",
    "        self.conv_decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=3, stride=2, padding=1, output_padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=4, stride=2, padding=1, output_padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = self.decoder_linear(z)\n",
    "        z = z.view(-1, 64, 4, 4)\n",
    "        return self.conv_decoder(z)\n",
    "\n",
    "class ConvVAE(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.conv_encoder = ConvEncoder(latent_dim)\n",
    "        self.conv_decoder = ConvDecoder(latent_dim)\n",
    "\n",
    "    def reparameterize(self, mean, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mean + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.conv_encoder(x)\n",
    "        mean, log_var = z.chunk(2, dim=1)\n",
    "        z = self.reparameterize(mean, log_var)\n",
    "        x_reconstructed = self.conv_decoder(z)\n",
    "        return x_reconstructed, mean, log_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 211041\n",
      "Trainable parameters: 211041\n"
     ]
    }
   ],
   "source": [
    "cv = ConvVAE(latent_dim=32).to(device)\n",
    "# Count the parameters\n",
    "total_params = sum(p.numel() for p in cv.parameters())\n",
    "trainable_params = sum(p.numel() for p in cv.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "print(f\"Trainable parameters: {trainable_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(x_reconstructed, x, mean, log_var):\n",
    "    BCE = F.binary_cross_entropy(x_reconstructed, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
    "    return BCE + KLD\n",
    "\n",
    "cv = ConvVAE(latent_dim=32).to(device)\n",
    "optimizer = optim.Adam(cv.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch 1 Average loss: 169.73536875\n",
      "====> Test set loss: 118.7123\n",
      "====> Epoch 2 Average loss: 113.51606318359374\n",
      "====> Test set loss: 109.2178\n",
      "====> Epoch 3 Average loss: 108.18388380533854\n",
      "====> Test set loss: 105.8626\n",
      "====> Epoch 4 Average loss: 106.10699200846354\n",
      "====> Test set loss: 104.4580\n",
      "====> Epoch 5 Average loss: 104.8271139811198\n",
      "====> Test set loss: 103.7765\n",
      "====> Epoch 6 Average loss: 103.9559329264323\n",
      "====> Test set loss: 102.9773\n",
      "====> Epoch 7 Average loss: 103.28059630533855\n",
      "====> Test set loss: 102.2406\n",
      "====> Epoch 8 Average loss: 102.67418059895833\n",
      "====> Test set loss: 101.6645\n",
      "====> Epoch 9 Average loss: 102.24797571614583\n",
      "====> Test set loss: 101.7180\n",
      "====> Epoch 10 Average loss: 101.85603092447917\n",
      "====> Test set loss: 101.0529\n",
      "====> Epoch 11 Average loss: 101.49247330729166\n",
      "====> Test set loss: 101.1469\n",
      "====> Epoch 12 Average loss: 101.20227750651041\n",
      "====> Test set loss: 100.5631\n",
      "====> Epoch 13 Average loss: 100.89254306640625\n",
      "====> Test set loss: 100.9389\n",
      "====> Epoch 14 Average loss: 100.65281033528646\n",
      "====> Test set loss: 99.8609\n",
      "====> Epoch 15 Average loss: 100.44916647135416\n",
      "====> Test set loss: 99.5929\n",
      "====> Epoch 16 Average loss: 100.20810590820312\n",
      "====> Test set loss: 99.6809\n",
      "====> Epoch 17 Average loss: 100.01682223307292\n",
      "====> Test set loss: 99.4141\n",
      "====> Epoch 18 Average loss: 99.84903846028647\n",
      "====> Test set loss: 99.3328\n",
      "====> Epoch 19 Average loss: 99.66773237304687\n",
      "====> Test set loss: 99.0742\n",
      "====> Epoch 20 Average loss: 99.450503515625\n",
      "====> Test set loss: 99.3700\n",
      "====> Epoch 21 Average loss: 99.37000213216146\n",
      "====> Test set loss: 98.9509\n",
      "====> Epoch 22 Average loss: 99.23965475260417\n",
      "====> Test set loss: 99.0238\n",
      "====> Epoch 23 Average loss: 99.09333763020834\n",
      "====> Test set loss: 98.5929\n",
      "====> Epoch 24 Average loss: 98.97335250651042\n",
      "====> Test set loss: 98.5915\n",
      "====> Epoch 25 Average loss: 98.83136863606771\n",
      "====> Test set loss: 98.6427\n",
      "====> Epoch 26 Average loss: 98.74949039713542\n",
      "====> Test set loss: 98.3118\n",
      "====> Epoch 27 Average loss: 98.61572368164063\n",
      "====> Test set loss: 98.4385\n",
      "====> Epoch 28 Average loss: 98.58035227864583\n",
      "====> Test set loss: 98.4175\n",
      "====> Epoch 29 Average loss: 98.42219765625\n",
      "====> Test set loss: 98.0162\n",
      "====> Epoch 30 Average loss: 98.29910875651042\n",
      "====> Test set loss: 98.0583\n",
      "====> Epoch 31 Average loss: 98.30319371744791\n",
      "====> Test set loss: 97.7887\n",
      "====> Epoch 32 Average loss: 98.19913619791667\n",
      "====> Test set loss: 97.9721\n",
      "====> Epoch 33 Average loss: 98.08275063476563\n",
      "====> Test set loss: 97.7701\n",
      "====> Epoch 34 Average loss: 98.01815724283854\n",
      "====> Test set loss: 97.6500\n",
      "====> Epoch 35 Average loss: 97.9724979654948\n",
      "====> Test set loss: 97.8651\n",
      "====> Epoch 36 Average loss: 97.82557454427084\n",
      "====> Test set loss: 97.8930\n",
      "====> Epoch 37 Average loss: 97.7770110188802\n",
      "====> Test set loss: 97.5026\n",
      "====> Epoch 38 Average loss: 97.78881671549479\n",
      "====> Test set loss: 97.5792\n",
      "====> Epoch 39 Average loss: 97.69974290364583\n",
      "====> Test set loss: 97.6535\n",
      "====> Epoch 40 Average loss: 97.61776793619792\n",
      "====> Test set loss: 97.3437\n",
      "====> Epoch 41 Average loss: 97.56446499023437\n",
      "====> Test set loss: 97.2536\n",
      "====> Epoch 42 Average loss: 97.50813546549479\n",
      "====> Test set loss: 97.2818\n",
      "====> Epoch 43 Average loss: 97.46513527018229\n",
      "====> Test set loss: 97.2567\n",
      "====> Epoch 44 Average loss: 97.38708754882812\n",
      "====> Test set loss: 97.0870\n",
      "====> Epoch 45 Average loss: 97.32847016601562\n",
      "====> Test set loss: 97.1225\n",
      "====> Epoch 46 Average loss: 97.30706852213541\n",
      "====> Test set loss: 97.1872\n",
      "====> Epoch 47 Average loss: 97.2703378092448\n",
      "====> Test set loss: 97.1151\n",
      "====> Epoch 48 Average loss: 97.22114261067708\n",
      "====> Test set loss: 97.1400\n",
      "====> Epoch 49 Average loss: 97.13898536783854\n",
      "====> Test set loss: 96.9175\n"
     ]
    }
   ],
   "source": [
    "def train(epoch):\n",
    "    cv.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        x_reconstructed, mean, log_var = cv(data)\n",
    "        loss = loss_function(x_reconstructed, data, mean, log_var)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    print(f\"====> Epoch {epoch} Average loss: {train_loss / len(train_loader.dataset)}\")\n",
    "\n",
    "def test():\n",
    "    cv.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            x_reconstructed, mean, log_var = cv(data)\n",
    "            x_reconstructed = torch.clamp(x_reconstructed, 0, 1)  # Ensure values are between 0 and 1\n",
    "            test_loss += loss_function(x_reconstructed, data, mean, log_var).item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f\"====> Test set loss: {test_loss:.4f}\")\n",
    "\n",
    "for epoch in range(1, 50):\n",
    "    train(epoch)\n",
    "    test()  # Added test() call after each epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate and display a reconstructed image\n",
    "cv.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    # Get a random batch of test data\n",
    "    random_idx = torch.randint(0, len(test_loader.dataset), (1,)).item()\n",
    "    test_data = test_loader.dataset[random_idx][0].unsqueeze(0).to(device)\n",
    "    \n",
    "    # Generate a reconstruction\n",
    "    x_reconstructed, _, _ = cv(test_data)\n",
    "    \n",
    "    # Ensure the values are between 0 and 1\n",
    "    x_reconstructed = torch.clamp(x_reconstructed, 0, 1)\n",
    "    \n",
    "    # Convert to numpy arrays for plotting\n",
    "    original = test_data[0].cpu().numpy().reshape(28, 28)\n",
    "    reconstructed = x_reconstructed[0].cpu().numpy().reshape(28, 28)\n",
    "\n",
    "    # Create a figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "    # Plot the original image\n",
    "    ax1.imshow(original, cmap='gray')\n",
    "    ax1.set_title('Original')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Plot the reconstructed image\n",
    "    ax2.imshow(reconstructed, cmap='gray')\n",
    "    ax2.set_title('Reconstructed')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate an image from a random noise vector\n",
    "cv.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    # Generate a random noise vector\n",
    "    z = torch.randn(1, 32).to(device)\n",
    "    \n",
    "    # Generate an image from the noise vector\n",
    "    generated_image = cv.conv_decoder(z)\n",
    "    \n",
    "    # Ensure the values are between 0 and 1\n",
    "    generated_image = torch.clamp(generated_image, 0, 1)\n",
    "    \n",
    "    # Convert to numpy array for plotting\n",
    "    generated_image = generated_image[0].cpu().numpy().reshape(28, 28)\n",
    "\n",
    "    # Create a figure\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    \n",
    "    # Plot the generated image\n",
    "    plt.imshow(generated_image, cmap='gray')\n",
    "    plt.title('Generated Image from Random Noise')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Z2CNNLayer(nn.Module):\n",
    "    def __init__(self, in_channels, kernel_size=3, use_maxpool=True):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 20, kernel_size=kernel_size, bias=False),\n",
    "            nn.BatchNorm2d(20),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) if use_maxpool else nn.Identity(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "\n",
    "class Z2CNN(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            Z2CNNLayer(1, use_maxpool=False),\n",
    "            Z2CNNLayer(20),\n",
    "            Z2CNNLayer(20),\n",
    "            Z2CNNLayer(20),\n",
    "            Z2CNNLayer(20),\n",
    "            Z2CNNLayer(20),\n",
    "            Z2CNNLayer(20, kernel_size=4),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
